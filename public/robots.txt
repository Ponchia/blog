# robots.txt for https://brontolotto.observer/
# Optimized for search engine crawling and indexing

User-agent: *
Allow: /

# Optimize crawl efficiency - prevent crawling of search result pages and tag pages
Disallow: /search
Disallow: /tags

# Prevent duplicate content issues
Disallow: /*?*

# Sitemap location (helps search engines discover all pages)
Sitemap: https://brontolotto.observer/sitemap-index.xml

# Optional: Specify crawl rate for specific bots
# Note: Most modern search engines ignore this directive and use their own algorithms
# User-agent: Googlebot
# Crawl-delay: 1

# Host directive (helps with canonical domain)
Host: brontolotto.observer